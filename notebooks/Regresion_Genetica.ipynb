{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIl_EhC6gWEY"
      },
      "source": [
        "# Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hkpCtg-Uph3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install gdown --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqk6XqMeTqEC"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle\n",
        "from google.colab import files\n",
        "import gdown\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlMEfK26gYtK"
      },
      "outputs": [],
      "source": [
        "# Descargamos el Dataset de Train/Val desde el enlace\n",
        "url = \"https://drive.google.com/uc?export=download&id=16By7bbG6lG6PkVF-17uDLVPN7fMH98j-\"\n",
        "# Leemos el Dataset\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Descargamos el Dataset de Test desde el enlace\n",
        "url = \"https://drive.google.com/uc?export=download&id=1hSvTbDT2Je4ILWOmIP_bWyxhu9ViaUqF\"\n",
        "# Leemos el Dataset\n",
        "df_test = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOeXONayL4U9"
      },
      "outputs": [],
      "source": [
        "# Descargamos las medias generacionales saltando la primera fila (que solo contiene los índices de generaciones)\n",
        "url = \"https://drive.google.com/uc?export=download&id=13E8bSkQ-jX313whRzVTuNdQ1jaKhEHQ-\"\n",
        "# Leemos el Dataset\n",
        "df_medias = pd.read_csv(url, header=None, skiprows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LfRczZPihQe"
      },
      "source": [
        "# Visualización inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFOWMzwzgvDE"
      },
      "outputs": [],
      "source": [
        "# Ver tamaño\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7AE06WAjOYg"
      },
      "outputs": [],
      "source": [
        "df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmHW9X6IgzMf"
      },
      "outputs": [],
      "source": [
        "# Ver tipos de datos\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rudbTPiag7Df"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNPffbnHkY1h"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqnAbtqSg_Jm"
      },
      "outputs": [],
      "source": [
        "# Nulos por columna\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqHODFKZjyEC"
      },
      "source": [
        "# Preprocesamiento del Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DHKd7iajxs5"
      },
      "outputs": [],
      "source": [
        "# Eliminamos la columna ID porque no nos sirve de nada\n",
        "df = df.drop(columns=['ID'])\n",
        "df_test = df_test.drop(columns=['ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXp3102-Stuq"
      },
      "outputs": [],
      "source": [
        "# Nombrar las filas del df de medias\n",
        "df_medias.index = [\"celtas\", \"iberos\", \"fenicios\", \"griegos\", \"italicos\"]\n",
        "# Transponer para que cada generación sea una fila\n",
        "df_medias_T = df_medias.T.reset_index(drop=True)\n",
        "df_medias_T.columns = [\"celtas\", \"iberos\", \"fenicios\", \"griegos\", \"italicos\"]\n",
        "df_medias_T.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mYBJ9esmJ8"
      },
      "source": [
        "# Análisis de la distribución de la variable objetivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vATfUJWAt8Et"
      },
      "outputs": [],
      "source": [
        "print(df[\"distancia_G1\"].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDIcdgFGQqoE"
      },
      "source": [
        "El 75% de los valores de la variable están entre 1 y 25, el otro 25% están entre 25 y 117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRPcwKs5tPHd"
      },
      "outputs": [],
      "source": [
        "plt.hist(df[\"distancia_G1\"], bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Distribución de distancia_G1\")\n",
        "plt.xlabel(\"Valor\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K1d4xnstmRD"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=df[\"distancia_G1\"], color='lightgreen')\n",
        "plt.title(\"Boxplot de distancia_G1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Qs_UHMJAUW"
      },
      "source": [
        "Podemos ver claramente que la variable objetivo (distancia_G1) tiene una distribución muy asimétrica, hay muchisimos más valores bajos que valores altos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWCE0IVAudMq"
      },
      "source": [
        "# Preparación del Dataframe para los entrenamientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSfl4DB8kqvd"
      },
      "outputs": [],
      "source": [
        "# Definir variables X e y\n",
        "\n",
        "# Dataframe principal\n",
        "X = df[[\"celtas\", \"iberos\", \"fenicios\", \"griegos\", \"italicos\"]]\n",
        "y = df[\"distancia_G1\"]\n",
        "\n",
        "# Dataframe de test\n",
        "X_test = df_test[[\"celtas\", \"iberos\", \"fenicios\", \"griegos\", \"italicos\"]]\n",
        "y_test = df_test[\"distancia_G1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5SxRsR4lUTp"
      },
      "outputs": [],
      "source": [
        "# Dividimos el Dataframe\n",
        "# Train 80%, Val 20%\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape[0], \"filas\")\n",
        "print(\"Validación:\", X_val.shape[0], \"filas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayGlRUsqnOzI"
      },
      "outputs": [],
      "source": [
        "# Inicializar el escalador\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Escalamos solo con los datos de entrenamiento\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transformamos validación y test con el mismo escalador\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Transformamos también las medias generacionales que se encuentran en df_medias_T\n",
        "medias_scaled = scaler.transform(df_medias_T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wJosyyJns16"
      },
      "source": [
        "# Definir y entrenar el Modelo LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpNwRwMSn810"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NFi6a-Yn-QI"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If2jvrRjGXuf"
      },
      "source": [
        "## Ver los resultados de predicción en los datos de validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnfrM4zAohno"
      },
      "outputs": [],
      "source": [
        "r2 = r2_score(y_val, y_pred)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "print(\"Resultados en validación:\")\n",
        "print(f\"R²   = {r2:.3f}\")\n",
        "print(f\"MAE  = {mae:.3f}\")\n",
        "print(f\"RMSE = {rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuF8qLuJJrwe"
      },
      "source": [
        "Teniendo en cuenta que la variable objetivo es muy asimetrica, estos resultados tan malos nos hacen sospechar que los valores más altos (outliers), que estan menos respresentados y muy alejados del grueso de valores, pueden estar dificultando el aprendizaje del modelo lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-u4002ZwkxU"
      },
      "outputs": [],
      "source": [
        "# Crear máscaras para valores bajos y altos\n",
        "low_mask = y_val <= 25.15\n",
        "high_mask = y_val > 25.15\n",
        "\n",
        "# Calcular MAE por segmento\n",
        "mae_low = mean_absolute_error(y_val[low_mask], y_pred[low_mask])\n",
        "mae_high = mean_absolute_error(y_val[high_mask], y_pred[high_mask])\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Errores segmentados por rango de distancia_G1:\")\n",
        "print(f\"MAE en valores bajos (≤ 25): {mae_low:.3f}\")\n",
        "print(f\"MAE en valores altos (> 25): {mae_high:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUEGInZbKj7o"
      },
      "source": [
        "Las sospechas eran ciertas, en los valores por debajo de 25 el modelo predice ligeramente mal, sin embargo en los que están por encima el modelo predice muy mal (tres veces peor), esto como dijimos antes, pasa porque los valores altos son menos frecuentes y muy diferentes en escala, por lo que el modelo lineal (que asume una relación proporcional constante) no puede ajustarse bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tv_ApFnEv9v"
      },
      "source": [
        "# Definir y entrenar el Modelo GradientBoosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9sJ9b1LTJH"
      },
      "source": [
        "Con la idea de obtener unos resultados decentes vamos a optar por un modelo Gradient Boosting, el cual nos ofrece las siguientes ventajas:\n",
        "\n",
        "- Maneja relaciones no lineales entre variables.\n",
        "\n",
        "- Funciona bien con rangos de valores muy distintos.\n",
        "\n",
        "- Se puede obtener muy buena precisión si se ajustan bien los hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lufgtx5FgiI"
      },
      "outputs": [],
      "source": [
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=100,     # número de árboles\n",
        "    learning_rate=0.1,    # velocidad de aprendizaje\n",
        "    max_depth=3,          # profundidad máxima de cada árbol\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG665m95MDM9"
      },
      "source": [
        "Debido a que el tamaño del Dataframe no es enorme (tiene 560 filas para entrenar), un modelo muy profundo o con muchos árboles puede sobreajustar, asi que no conviene pasarse usando hiparametros demasiado grandes.\n",
        "\n",
        "Además por la misma razón, conviene escalar los datos, como ya hemos hecho antes, para evitar modelos extremadamente complejos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUxFX4OxFlCJ"
      },
      "outputs": [],
      "source": [
        "gb_model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOXDrT1XFpT2"
      },
      "outputs": [],
      "source": [
        "y_pred = gb_model.predict(X_val_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRxSPk4aGjuM"
      },
      "source": [
        "## Ver los resultados de predicción en los datos de validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YajiRpt8FrLr"
      },
      "outputs": [],
      "source": [
        "r2 = r2_score(y_val, y_pred)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "print(\"Resultados Gradient Boosting en validación:\")\n",
        "print(f\"R²   = {r2:.3f}\")\n",
        "print(f\"MAE  = {mae:.3f}\")\n",
        "print(f\"RMSE = {rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lnk1TBxNMAi"
      },
      "source": [
        "Ahora podemos ver como los resultados han mejorado enormemente, con una mayor explicación de la variabilidad y un menor error promedio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVyrvF43Fx0-"
      },
      "outputs": [],
      "source": [
        "low_mask = y_val <= 25.15\n",
        "high_mask = y_val > 25.15\n",
        "\n",
        "mae_low = mean_absolute_error(y_val[low_mask], y_pred[low_mask])\n",
        "mae_high = mean_absolute_error(y_val[high_mask], y_pred[high_mask])\n",
        "\n",
        "print(\"Errores segmentados por rango de distancia_G1:\")\n",
        "print(f\"MAE en valores bajos (≤ 25): {mae_low:.3f}\")\n",
        "print(f\"MAE en valores altos (> 25): {mae_high:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaxfrGtYNyeQ"
      },
      "source": [
        "Ahora el modelo captura bien tanto los valores bajos como los altos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdKQCHm7HUWn"
      },
      "source": [
        "## Búsqueda de los mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66mnIEQTN7tF"
      },
      "source": [
        "Ya que hemos visto que el modelo funciona bien, vamos a hacer una búsqueda de hiperparámetros para Gradient Boosting usando GridSearchCV, lo cuál nos permitirá encontrar la combinación que maximice el rendimiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJC_PknOHiYk"
      },
      "outputs": [],
      "source": [
        "# Definir el modelo base\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Definir el marco de hiperparámetros a probar\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"max_depth\": [2, 3, 4],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Configurar GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gb,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_absolute_error\",  # buscamos minimizar MAE\n",
        "    cv=5,                               # validación cruzada 5-fold\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK4QyQhTH7vg"
      },
      "outputs": [],
      "source": [
        "grid_search.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvU8dhCTIPpr"
      },
      "outputs": [],
      "source": [
        "# Mejor combinación de hiperparámetros\n",
        "print(\"Mejores hiperparámetros encontrados:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AoecGEoIUTR"
      },
      "outputs": [],
      "source": [
        "# Evaluar en validación\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_val_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5NZJfKQIlNI"
      },
      "outputs": [],
      "source": [
        "r2 = r2_score(y_val, y_pred)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "\n",
        "print(\"Resultados con los mejores hiperparámetros:\")\n",
        "print(f\"R²   = {r2:.3f}\")\n",
        "print(f\"MAE  = {mae:.3f}\")\n",
        "print(f\"RMSE = {rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJV5ftjKPZEp"
      },
      "source": [
        "Con el ajuste de hiperparámetros hemos reducido el error promedio general considerablemente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3fqZHDSOWy_"
      },
      "outputs": [],
      "source": [
        "low_mask = y_val <= 25.15\n",
        "high_mask = y_val > 25.15\n",
        "\n",
        "mae_low = mean_absolute_error(y_val[low_mask], y_pred[low_mask])\n",
        "mae_high = mean_absolute_error(y_val[high_mask], y_pred[high_mask])\n",
        "\n",
        "print(\"Errores segmentados por rango de distancia_G1:\")\n",
        "print(f\"MAE en valores bajos (≤ 25): {mae_low:.3f}\")\n",
        "print(f\"MAE en valores altos (> 25): {mae_high:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1wtHSffOuSe"
      },
      "source": [
        "Además hemos conseguido reducir todavía más el error promedio en valores bajos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZWIYFV1fPe"
      },
      "source": [
        "# Probar el Modelo en el conjunto de Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWuI2OEo1j87"
      },
      "outputs": [],
      "source": [
        "y_test_pred = best_model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0d-Nosp1sAC"
      },
      "outputs": [],
      "source": [
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "print(\"Resultados en Test:\")\n",
        "print(f\"R²   = {r2_test:.3f}\")\n",
        "print(f\"MAE  = {mae_test:.3f}\")\n",
        "print(f\"RMSE = {rmse_test:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU_Ht7pA10A4"
      },
      "outputs": [],
      "source": [
        "low_mask_test = y_test <= 25.15\n",
        "high_mask_test = y_test > 25.15\n",
        "\n",
        "mae_low_test = mean_absolute_error(y_test[low_mask_test], y_test_pred[low_mask_test])\n",
        "mae_high_test = mean_absolute_error(y_test[high_mask_test], y_test_pred[high_mask_test])\n",
        "\n",
        "print(\"Errores segmentados en Test:\")\n",
        "print(f\"MAE en valores bajos (≤ 25): {mae_low_test:.3f}\")\n",
        "print(f\"MAE en valores altos (> 25): {mae_high_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQgTgUsL2Fjh"
      },
      "source": [
        "En base a los buenos resultados obtenidos podemos interpretar lo siguiente:\n",
        "\n",
        "- El modelo generaliza correctamente ya que las métricas bajaron un poco (como es normal), pero siguen muy altas\n",
        "- No hay sobreajuste ya que si lo hubiera el R² se hubiera desplomado\n",
        "- Hay consistencia en los valores altos, ya que el MAE apenas cambió con respecto a los resultados de validación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJtmij8i3GVD"
      },
      "source": [
        "# Serialización del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOc7PnaE3_xO"
      },
      "outputs": [],
      "source": [
        "# Crear un diccionario con los objetos a guardar\n",
        "modelo_completo = {\n",
        "    \"model\": best_model,\n",
        "    \"scaler\": scaler\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B1Tczzn4FNF"
      },
      "outputs": [],
      "source": [
        "# Guardar en Colab\n",
        "archivo_pickle = \"gradient_boosting_model.pkl\"\n",
        "with open(archivo_pickle, \"wb\") as f:\n",
        "    pickle.dump(modelo_completo, f)\n",
        "\n",
        "# Descargar automáticamente\n",
        "files.download(archivo_pickle)\n",
        "\n",
        "print(\"Modelo y preprocesadores guardados correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SDcQ4SR5Dwv"
      },
      "source": [
        "# Cargar modelo .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAPAmX4N5u2U"
      },
      "outputs": [],
      "source": [
        "url = \"https://drive.google.com/uc?export=download&id=1yB477t_Ese8qFf9xQoMg1fXuo9EXQoDH\"\n",
        "output = \"gradboost_model_genes.pkl\"\n",
        "\n",
        "# Descargar desde Drive\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Cargar el modelo y preprocesadores\n",
        "with open(output, \"rb\") as f:\n",
        "    data_cargada = pickle.load(f)\n",
        "\n",
        "modelo_cargado = data_cargada[\"model\"]\n",
        "scaler_cargado = data_cargada[\"scaler\"]\n",
        "\n",
        "print(\"\\nModelo y preprocesadores cargados correctamente desde Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilc9dH7t6m5V"
      },
      "outputs": [],
      "source": [
        "# Probar modelo cargado en el conjunto de test\n",
        "y_test_pkl = modelo_cargado.predict(X_test_scaled)\n",
        "\n",
        "r2_test = r2_score(y_test, y_test_pkl)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pkl)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pkl))\n",
        "\n",
        "print(\"Resultados en Test:\")\n",
        "print(f\"R²   = {r2_test:.3f}\")\n",
        "print(f\"MAE  = {mae_test:.3f}\")\n",
        "print(f\"RMSE = {rmse_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlQQkjN3NA-4"
      },
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lg21jBWPDUE"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "medias_pca = pca.fit_transform(medias_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83ljrpV4PEdy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "# G1 = referencia ancestral\n",
        "plt.scatter(medias_pca[0, 0], medias_pca[0, 1],\n",
        "            color=\"red\", s=150, marker=\"X\", label=\"Generación 1 (ancestral)\")\n",
        "\n",
        "# Otras generaciones\n",
        "plt.scatter(medias_pca[1:, 0], medias_pca[1:, 1],\n",
        "            color=\"gray\", label=\"Otras generaciones\", alpha=0.7)\n",
        "\n",
        "# Etiquetas G1–G9 (centradas sobre el punto)\n",
        "for i in range(medias_pca.shape[0]):\n",
        "    plt.text(medias_pca[i, 0], medias_pca[i, 1],\n",
        "             f\"G{i+1}\",\n",
        "             fontsize=9, ha=\"center\", va=\"center\",\n",
        "             bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", pad=1))\n",
        "\n",
        "plt.xlabel(\"Componente principal 1\")\n",
        "plt.ylabel(\"Componente principal 2\")\n",
        "plt.title(\"PCA: Generaciones\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkT3N4V9WGc4"
      },
      "outputs": [],
      "source": [
        "# Tomamos un individuo del test\n",
        "i = 96  # por ejemplo, el individuo número X\n",
        "individuo = X_test_scaled[i].reshape(1, -1)  # mantener formato 2D\n",
        "\n",
        "# Lo proyectamos al mismo espacio PCA\n",
        "individuo_pca = pca.transform(individuo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD-aTMtgWkDn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "# Generación ancestral (G1)\n",
        "plt.scatter(medias_pca[0, 0], medias_pca[0, 1],\n",
        "            color=\"red\", s=150, marker=\"X\", label=\"Generación 1 (ancestral)\")\n",
        "\n",
        "# Otras generaciones\n",
        "plt.scatter(medias_pca[1:, 0], medias_pca[1:, 1],\n",
        "            color=\"gray\", label=\"Otras generaciones\", alpha=0.7)\n",
        "\n",
        "# Individuo de test\n",
        "plt.scatter(individuo_pca[0, 0], individuo_pca[0, 1],\n",
        "            color=\"blue\", s=100, label=f\"Individuo test #{i}\")\n",
        "\n",
        "# Etiquetas de generaciones\n",
        "for j in range(medias_pca.shape[0]):\n",
        "    plt.text(medias_pca[j, 0], medias_pca[j, 1],\n",
        "             f\"G{j+1}\", fontsize=9, ha=\"center\", va=\"center\",\n",
        "             bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", pad=1))\n",
        "\n",
        "plt.xlabel(\"Componente principal 1\")\n",
        "plt.ylabel(\"Componente principal 2\")\n",
        "plt.title(\"PCA: Generaciones y un individuo de test\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtpV0mIAXfUC"
      },
      "outputs": [],
      "source": [
        "# Guardar en Colab el PCA entrenado\n",
        "archivo_pca = \"pca.pkl\"\n",
        "with open(archivo_pca, \"wb\") as f:\n",
        "    pickle.dump(pca, f)\n",
        "\n",
        "# Descargar automáticamente\n",
        "files.download(archivo_pca)\n",
        "\n",
        "print(\"PCA guardado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRShuAKVYxvn"
      },
      "outputs": [],
      "source": [
        "# Guardar las coordenadas PCA de las generaciones\n",
        "df_medias_pca = pd.DataFrame(medias_pca, columns=[\"PC1\", \"PC2\"])\n",
        "df_medias_pca.to_csv(\"medias_pca.csv\", index=False)\n",
        "\n",
        "# Descargar automáticamente\n",
        "files.download(\"medias_pca.csv\")\n",
        "\n",
        "print(\"Coordenadas PCA de las generaciones guardadas correctamente\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
